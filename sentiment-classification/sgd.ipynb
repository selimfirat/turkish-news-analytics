{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import Data \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from plot_learning_curve import plot_learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def classify(train_x, train_y, test_x, test_y, classifier_params):\n",
    "    \n",
    "    cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "    est = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=100, **classifier_params)\n",
    "\n",
    "    #plot_learning_curve(est, \"Stochastic Gradient Descent\", train_x, train_y, cv=cv)\n",
    "    #plt.show()\n",
    "    \n",
    "    est = est.fit(X=train_x, y = train_y)\n",
    "    pred_y = est.predict(test_x)\n",
    "    print(classification_report(pred_y, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENTS = [\n",
    "{\n",
    "    \"vectorizer_func\": \"count_vectorized\",\n",
    "    \"vectorizer\": {\n",
    "        \"ngram_range\": (1, 1)\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"normalized\": True\n",
    "    },\n",
    "    \"estimator\": {\n",
    "    }\n",
    "},\n",
    "{\n",
    "    \"vectorizer_func\": \"count_vectorized\",\n",
    "    \"vectorizer\": {\n",
    "        \"ngram_range\": (2, 2)\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"normalized\": True\n",
    "    },\n",
    "    \"estimator\": {\n",
    "    }\n",
    "},\n",
    "{\n",
    "    \"vectorizer_func\": \"tfidf_vectorized\",\n",
    "    \"vectorizer\": {\n",
    "        \"ngram_range\": (1, 1)\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"normalized\": True\n",
    "    },\n",
    "    \"estimator\": {\n",
    "    }\n",
    "},\n",
    "{\n",
    "    \"vectorizer_func\": \"tfidf_vectorized\",\n",
    "    \"vectorizer\": {\n",
    "        \"ngram_range\": (2, 2)\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"normalized\": True\n",
    "    },\n",
    "    \"estimator\": {\n",
    "    }\n",
    "},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "{\"estimator\": {}, \"vectorizer_func\": \"count_vectorized\", \"data\": {\"normalized\": true}, \"vectorizer\": {\"ngram_range\": [1, 1]}}\n",
      "--\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   NEGATIVE       0.75      0.69      0.72       657\n",
      "       NOTR       0.32      0.41      0.36       222\n",
      "   POSITIVE       0.61      0.58      0.60       320\n",
      "\n",
      "avg / total       0.63      0.61      0.62      1199\n",
      "\n",
      "---------------\n",
      "---------------\n",
      "{\"estimator\": {}, \"vectorizer_func\": \"count_vectorized\", \"data\": {\"normalized\": true}, \"vectorizer\": {\"ngram_range\": [2, 2]}}\n",
      "--\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   NEGATIVE       0.91      0.62      0.73       892\n",
      "       NOTR       0.10      0.52      0.17        58\n",
      "   POSITIVE       0.52      0.63      0.57       249\n",
      "\n",
      "avg / total       0.79      0.61      0.67      1199\n",
      "\n",
      "---------------\n",
      "---------------\n",
      "{\"estimator\": {}, \"vectorizer_func\": \"tfidf_vectorized\", \"data\": {\"normalized\": true}, \"vectorizer\": {\"ngram_range\": [1, 1]}}\n",
      "--\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   NEGATIVE       0.80      0.68      0.74       715\n",
      "       NOTR       0.28      0.43      0.34       192\n",
      "   POSITIVE       0.61      0.63      0.62       292\n",
      "\n",
      "avg / total       0.67      0.63      0.64      1199\n",
      "\n",
      "---------------\n",
      "---------------\n",
      "{\"estimator\": {}, \"vectorizer_func\": \"tfidf_vectorized\", \"data\": {\"normalized\": true}, \"vectorizer\": {\"ngram_range\": [2, 2]}}\n",
      "--\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   NEGATIVE       0.92      0.60      0.73       928\n",
      "       NOTR       0.10      0.62      0.17        45\n",
      "   POSITIVE       0.47      0.63      0.54       226\n",
      "\n",
      "avg / total       0.81      0.61      0.67      1199\n",
      "\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "for param_set in EXPERIMENTS:\n",
    "    print(\"-\" * 15)\n",
    "    print(json.dumps(param_set))\n",
    "    print(\"--\")\n",
    "    data = Data(**param_set[\"data\"])\n",
    "    vectorizer = getattr(data, param_set[\"vectorizer_func\"])\n",
    "    train_x, train_y, test_x, test_y = vectorizer(**param_set[\"vectorizer\"])\n",
    "    classify(train_x, train_y, test_x, test_y, param_set[\"estimator\"])\n",
    "    print(\"-\" * 15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
