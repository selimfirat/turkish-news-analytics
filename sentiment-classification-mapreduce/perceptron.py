import numpy as npdef f(x,w,b):    return sigmoid(np.dot(x, w) + b)def sigmoid(t):    return 1.0 / (1 + np.exp(-t))def l2loss(x,y,w,b):    y_hat = f(x, w, b)    r = y - y_hat    loss_l2 = np.dot(r.T, r)    w_grad = (y - y_hat) * (y_hat * (1-y_hat))    b_grad = (y - y_hat) * (y_hat * (1-y_hat))    return (loss_l2, w_grad, b_grad)def minimize_l2loss(x,y,w,b, num_iters=1000, eta=0.001):    w = w.reshape((-1, 1))    y = y.reshape((-1, 1))    for i in range(num_iters):        print("Num iter: ", i)        l, w_grad, b_grad = l2loss(x, y, w, b)        w = w + eta * np.dot(x.T, w_grad)        b = b + eta * np.sum(b_grad)    return w, b