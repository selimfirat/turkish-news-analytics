{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Selim\\Anaconda3\\envs\\py27\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from gensim.models import KeyedVectors\n",
    "word2vec = KeyedVectors.load_word2vec_format('tr_word2vec', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"word2vec.pickle\", \"wb+\") as w:\n",
    "    pickle.dump(word2vec, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions, GoogleCloudOptions, StandardOptions, SetupOptions\n",
    "from apache_beam.io.gcp.datastore.v1.datastoreio import ReadFromDatastore\n",
    "from apache_beam.metrics import Metrics\n",
    "from apache_beam.metrics.metric import MetricsFilter\n",
    "from google.cloud.proto.datastore.v1 import entity_pb2\n",
    "from google.cloud.proto.datastore.v1 import query_pb2\n",
    "from googledatastore import helper as datastore_helper\n",
    "from googledatastore import PropertyFilter\n",
    "from google.cloud import datastore\n",
    "from google.cloud.proto.datastore.v1 import query_pb2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.data\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "_sentence_tokenizer = nltk.data.load(\"./tokenizer/punkt_turkish.pickle\")\n",
    "word_tokenizer = WordPunctTokenizer()\n",
    "abbreviations = set()\n",
    "with open(\"./tokenizer/abbreviations-long.txt\") as f:\n",
    "    for l in f:\n",
    "        abbreviations.add(l.split(':')[0])\n",
    "\n",
    "_sentence_tokenizer._params.abbrev_types = abbreviations\n",
    "\n",
    "\n",
    "def sentences_from_text(self, text):\n",
    "    return _sentence_tokenizer.tokenize(text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceTokenizerDoFn(beam.DoFn):\n",
    "    \"\"\"Convert a news story into sentences.\"\"\"\n",
    "        \n",
    "    def process(self, element):\n",
    "        \"\"\"Returns an iterator over words in contents of Cloud Datastore entity.\n",
    "        The element is a line of text.  If the line is blank, note that, too.\n",
    "        Args:\n",
    "          element: the input element to be processed\n",
    "        Returns:\n",
    "          The processed element.\n",
    "        \"\"\"\n",
    "        tokenizer = Tokenizer()\n",
    "        sentences = tokenizer.sentences_from_text(element[\"content\"])\n",
    "\n",
    "        return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ObjConverter(beam.DoFn):\n",
    "    \"\"\"Convert a news story into sentences.\"\"\"\n",
    "        \n",
    "    def process(self, element):\n",
    "        \"\"\"Returns an iterator over words in contents of Cloud Datastore entity.\n",
    "        The element is a line of text.  If the line is blank, note that, too.\n",
    "        Args:\n",
    "          element: the input element to be processed\n",
    "        Returns:\n",
    "          The processed element.\n",
    "        \"\"\"\n",
    "\n",
    "        link = element.properties.get('link', None)\n",
    "        link = link.string_value if link else \"\"\n",
    "        \n",
    "        title = element.properties.get('title', None)\n",
    "        title = title.string_value if title else \"\"\n",
    "        \n",
    "        description = element.properties.get(\"description\", None)\n",
    "        link = description.string_value if description else \"\"\n",
    "        \n",
    "        content = element.properties.get(\"text\", \"\")\n",
    "        content = content.string_value if content else \"\"\n",
    "        \n",
    "        published = element.properties.get(\"published\")\n",
    "        published = published.string_value if published else \"\"\n",
    "\n",
    "\n",
    "        return {\n",
    "            \"link\": link,\n",
    "            \"title\": title,\n",
    "            \"description\": description,\n",
    "            \"content\": content,\n",
    "            \"published\": published\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = PipelineOptions()\n",
    "google_cloud_options = options.view_as(GoogleCloudOptions)\n",
    "google_cloud_options.project = 'news-197916'\n",
    "google_cloud_options.job_name = 'sso' + str(random.randint(1, 9999))\n",
    "google_cloud_options.staging_location = 'gs://news-197916.appspot.com/word_count/'\n",
    "google_cloud_options.temp_location = 'gs://news-197916.appspot.com/df_tmp'\n",
    "options.view_as(StandardOptions).runner = 'DataflowRunner'\n",
    "\n",
    "setup_options = options.view_as(SetupOptions)\n",
    "setup_options.requirements_file = \"requirements.txt\"\n",
    "# setup_options.save_main_session = True\n",
    "\n",
    "p = beam.Pipeline(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:datastoreio read transform is experimental.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = query_pb2.Query()\n",
    "query.kind.add().name = \"News_Entry\"\n",
    "\n",
    "objs = (p\n",
    "    | 'Read From Datastore' >> ReadFromDatastore(project = google_cloud_options.project, query=query)\n",
    "    | 'Convert to Object' >> beam.ParDo(ObjConverter())\n",
    "       )\n",
    "\n",
    "sentences = (objs\n",
    "    | 'Sentence Tokenization' >> beam.FlatMap(lambda x: sentences_from_text(x.content))\n",
    "            )\n",
    "\n",
    "results = (sentences\n",
    "    | 'Write Results' >> beam.io.WriteToText(\"gs://news-197916.appspot.com/sents.txt\")\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DataflowPipelineResult <Job\n",
       " createTime: u'2018-05-03T12:21:15.830228Z'\n",
       " currentStateTime: u'1970-01-01T00:00:00Z'\n",
       " id: u'2018-05-03_05_21_15-192254392226200960'\n",
       " location: u'us-central1'\n",
       " name: u'sso9484'\n",
       " projectId: u'news-197916'\n",
       " stageStates: []\n",
       " steps: []\n",
       " tempFiles: []\n",
       " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)> at 0xcc2c1d0L>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = p.run()\n",
    "# result.wait_until_finish()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<apache_beam.pipeline.Pipeline at 0xd2e0fd0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
